{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60611bed",
   "metadata": {},
   "source": [
    "## Time series generation using VAEs.\n",
    "This is a minimal example of unsupervised time series generation using VAEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6220fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import copy\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tsgm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c5332",
   "metadata": {},
   "source": [
    "#### 1. Choose architecture of encoder and decoder.\n",
    "Here, you can either use one of the architectures presented in `tsgm.models.architectures`, or define custom discriminator and generator architectures as `tf` models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = tsgm.models.zoo[\"vae_conv5\"](24, 5, 10)\n",
    "encoder, decoder = architecture.encoder, architecture.decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375b04e",
   "metadata": {},
   "source": [
    "#### 2. Load data:\n",
    "We are working with a toy dataset, and use `tsgm` utility called `tsgm.utils.gen_sine_dataset` to generate the data. Next, we featurewise scale the dataset so that each feature is in $[0, 1]$, using `tsgm.utils.TSFeatureWiseScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tsgm.utils.gen_sine_dataset(10000, 24, 5)\n",
    "scaler = tsgm.utils.TSFeatureWiseScaler()        \n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76dd508",
   "metadata": {},
   "source": [
    "#### 3. Define model and train it.\n",
    "We define conditional GAN model (`tsgm.models.cvae.BetaVAE`), compile it, and train using `.fit` model. Additionally, we use `tsgm.models.monitors.GANMonitor` to track training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0de98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = tsgm.models.cvae.BetaVAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "\n",
    "vae.fit(scaled_data, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7f14d",
   "metadata": {},
   "source": [
    "#### 4. Check reconstruction of the data.\n",
    "We reconstruct data using `vae.predict(scaled_data)`. For validating that VAE works, we check that original and reconstructed datasets are visually similar using `tsgm.utils.visualize_original_and_reconst_ts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8be86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_decoded = vae.predict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsgm.utils.visualize_original_and_reconst_ts(scaled_data, x_decoded, num=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
